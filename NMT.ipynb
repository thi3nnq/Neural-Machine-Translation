{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6705b0d2",
   "metadata": {},
   "source": [
    "## Cài đặt số thư viện cần thiết\n",
    "Mình sẽ không hướng dẫn cài PyTorch vì do hardware của mỗi người là khác nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2a218aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./anaconda3/envs/my_env/lib/python3.8/site-packages (3.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (8.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (57.4.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (4.61.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy) (1.20.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: pyvi in ./anaconda3/envs/my_env/lib/python3.8/site-packages (0.1.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from pyvi) (0.3.6)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from pyvi) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from scikit-learn->pyvi) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from scikit-learn->pyvi) (1.20.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from scikit-learn->pyvi) (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from scikit-learn->pyvi) (2.2.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
      "Requirement already satisfied: tabulate in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
      "Requirement already satisfied: six in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (4.61.2)\n",
      "Requirement already satisfied: pip in ./anaconda3/envs/my_env/lib/python3.8/site-packages (21.1.3)\n",
      "Collecting pip\n",
      "  Downloading pip-21.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in ./anaconda3/envs/my_env/lib/python3.8/site-packages (57.4.0)\n",
      "Requirement already satisfied: wheel in ./anaconda3/envs/my_env/lib/python3.8/site-packages (0.36.2)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.1.3\n",
      "    Uninstalling pip-21.1.3:\n",
      "      Successfully uninstalled pip-21.1.3\n",
      "Successfully installed pip-21.2.1\n",
      "Collecting ja-core-news-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ja_core_news_sm-3.1.0/ja_core_news_sm-3.1.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.9 MB 9.8 MB/s eta 0:00:01     |███████████████████████████████▊| 12.8 MB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from ja-core-news-sm==3.1.0) (3.1.1)\n",
      "Requirement already satisfied: sudachidict-core>=20200330 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from ja-core-news-sm==3.1.0) (20210608)\n",
      "Requirement already satisfied: sudachipy>=0.4.9 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from ja-core-news-sm==3.1.0) (0.5.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (4.61.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (1.20.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (8.0.8)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (57.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (3.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (2.4.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (3.10.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (2021.5.30)\n",
      "Requirement already satisfied: sortedcontainers~=2.1.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from sudachipy>=0.4.9->ja-core-news-sm==3.1.0) (2.1.0)\n",
      "Requirement already satisfied: dartsclone~=0.9.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from sudachipy>=0.4.9->ja-core-news-sm==3.1.0) (0.9.0)\n",
      "Requirement already satisfied: Cython in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from dartsclone~=0.9.0->sudachipy>=0.4.9->ja-core-news-sm==3.1.0) (0.29.23)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/my_env/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->ja-core-news-sm==3.1.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ja_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!pip install pyvi\n",
    "!pip install -U pip setuptools wheel\n",
    "!python -m spacy download ja_core_news_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0100b",
   "metadata": {},
   "source": [
    "## Dataset\n",
    " Trong bài này, mình sẽ dùng "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16f8ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_input = []\n",
    "\n",
    "with open(f\"data_vi.txt\") as f:\n",
    "    for line in f:\n",
    "        line = line.replace('  ', ' ').lower()\n",
    "        vi_input.append(line.strip())\n",
    "\n",
    "jp_input = []\n",
    "with open(f\"data_ja.txt\") as f:\n",
    "    for line in f:\n",
    "        jp_input.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20017cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "import spacy\n",
    "\n",
    "vi_tokenized = [ViTokenizer.tokenize(i).split() for i in vi_input]\n",
    "\n",
    "jp_tokenizer = spacy.load('ja_core_news_sm')\n",
    "\n",
    "jp_tokenized = [[] for i in range(len(jp_input))]\n",
    "\n",
    "for idx, data in enumerate(jp_input):\n",
    "    tokenized = jp_tokenizer(data)\n",
    "    for token in tokenized:\n",
    "        jp_tokenized[idx].append(str(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140d772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "792f654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "SRC_LANGUAGE = 'jp'\n",
    "TGT_LANGUAGE = 'vn'\n",
    "\n",
    "vocab_transform = {}\n",
    "\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "def yield_tokens(lang_tokenized):\n",
    "    for i in lang_tokenized:\n",
    "        yield i\n",
    "\n",
    "vocab_transform[SRC_LANGUAGE] = build_vocab_from_iterator(yield_tokens(jp_tokenized), min_freq=1, specials=special_symbols, special_first=True)\n",
    "vocab_transform[TGT_LANGUAGE] = build_vocab_from_iterator(yield_tokens(vi_tokenized), min_freq=1, specials=special_symbols, special_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6861968",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_transform[SRC_LANGUAGE].set_default_index(UNK_IDX)\n",
    "vocab_transform[TGT_LANGUAGE].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ab017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3daaafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def attention(q, k, v, mask=None, dropout=None):\n",
    "    d_k = q.size(-1)\n",
    "    dot_product = torch.bmm(q, k.transpose(1, 2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        for i in range(0, dot_product.size(0), mask.size(0)):\n",
    "            dot_product[i: i+mask.size(0)] = (dot_product[i: i+mask.size(0)]).masked_fill(mask == 0, -1e9)\n",
    "        scores = dot_product\n",
    "    else:\n",
    "        scores = dot_product\n",
    "        \n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.bmm(p_attn, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f52bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.linears = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(4)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        q = self.linears[0](q)\n",
    "        k = self.linears[1](k)\n",
    "        v = self.linears[2](v)\n",
    "        def _split_heads(tensor):\n",
    "            bsz, length, embed_dim = tensor.size()\n",
    "            tensor = tensor.reshape(bsz, length, self.num_heads, self.d_k).transpose(1, 2).reshape(bsz * self.num_heads, -1, self.d_k)\n",
    "            return tensor\n",
    "        q = _split_heads(q)\n",
    "        k = _split_heads(k)\n",
    "        v = _split_heads(v)\n",
    "\n",
    "        output = attention(q, k, v, mask=mask,  dropout=self.dropout)\n",
    "\n",
    "        bsz_heads, length, d_k = output.size()\n",
    "        bsz = bsz_heads // num_heads\n",
    "        output = output.reshape(bsz, num_heads, length, self.d_k).transpose(1, 2).reshape(bsz, length, -1)\n",
    "\n",
    "        return self.linears[3](output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e27722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_in = nn.Linear(d_model, d_ff)\n",
    "        self.linear_out = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = F.gelu(self.linear_in(x))\n",
    "        return self.linear_out(self.dropout(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b2d33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = nn.LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f72cae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_heads, dropout=0.1):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.SelfMultiHeadAttention = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.FeedForward = FeedForward(d_model, d_ff, dropout)\n",
    "        self.sublayer = nn.ModuleList([SublayerConnection(d_model, dropout) for _ in range(2)])\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.SelfMultiHeadAttention(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.FeedForward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6321d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_heads, num_layers, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([EncoderBlock(d_model, d_ff, num_heads, dropout) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6c1f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_heads, dropout=0.1):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.SelfMultiHeadAttention = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.MultiHeadAttention = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.FeedForward = FeedForward(d_model, d_ff, dropout)\n",
    "        self.sublayer = nn.ModuleList([SublayerConnection(d_model, dropout) for _ in range(3)])\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, x, memory, tgt_mask, padding_mask=None):\n",
    "        x = self.sublayer[0](x, lambda x: self.SelfMultiHeadAttention(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.MultiHeadAttention(x, memory, memory, padding_mask))\n",
    "        return self.sublayer[2](x, self.FeedForward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1f1054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_heads, num_layers, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([DecoderBlock(d_model, d_ff, num_heads, dropout) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, memory, tgt_mask, padding_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, tgt_mask, padding_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17762d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        den = torch.exp(- torch.arange(0, d_model, 2) * math.log(10000) / d_model)\n",
    "        pos = torch.arange(0, max_len).reshape(max_len, 1)\n",
    "        pos_embedding = torch.zeros((max_len, d_model))\n",
    "        pos_embedding[:, 0::2] = torch.sin(den * pos)\n",
    "        pos_embedding[:, 1::2] = torch.cos(den * pos)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(1), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae7c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        return self.token_embedding(tokens.long()) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b98c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers,\n",
    "                 num_decoder_layers,\n",
    "                 d_model, d_ff,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 num_heads, dropout):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "        self.src_tok_emb = TokenEmbedding(d_model, src_vocab_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(d_model, tgt_vocab_size)\n",
    "        self.encoder = Encoder(d_model, d_ff, num_heads, num_encoder_layers, dropout)\n",
    "        self.decoder = Decoder(d_model, d_ff, num_heads, num_decoder_layers, dropout)\n",
    "        self.generator = nn.Linear(d_model, tgt_vocab_size)\n",
    "    \n",
    "    def forward(self, src_input_tensor, tgt_input_tensor, src_mask, tgt_mask, padding_mask=None):\n",
    "        src_emb = self.pos_encoding(self.src_tok_emb(src_input_tensor))\n",
    "        tgt_emb = self.pos_encoding(self.tgt_tok_emb(tgt_input_tensor))\n",
    "        output_encoder = self.encoder(src_emb, src_mask)\n",
    "        output_decoder = self.decoder(tgt_emb, output_encoder, tgt_mask, padding_mask)\n",
    "        return self.generator(output_decoder)\n",
    "    \n",
    "    def encode(self, src_input_tensor, src_mask):\n",
    "        src_emb = self.pos_encoding(self.src_tok_emb(src_input_tensor))\n",
    "        output_encoder = self.encoder(src_emb, src_mask)\n",
    "        return output_encoder\n",
    "    def decode(self, tgt_input_tensor, tgt_mask, memory, padding_mask=None):\n",
    "        tgt_emb = self.pos_encoding(self.tgt_tok_emb(tgt_input_tensor))\n",
    "        output_decoder = self.decoder(tgt_emb, memory, tgt_mask, padding_mask)\n",
    "        return self.generator(output_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50a513d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(batch, lang):  \n",
    "    assert lang == 'src' or lang == 'tgt'\n",
    "    bsz, length = batch.size()\n",
    "    mask = torch.ones(bsz, length, length)   \n",
    "    if lang == 'src':\n",
    "        return mask.to(DEVICE)\n",
    "    else:\n",
    "        return torch.triu(mask).transpose(1, 2).to(DEVICE)\n",
    "\n",
    "def create_padding_mask(batch):\n",
    "    bsz, length = batch.size()\n",
    "    padding_mask = (batch != PAD_IDX).unsqueeze(-1)\n",
    "    return padding_mask.to(DEVICE)\n",
    "\n",
    "def create_std_mask(padding_mask, mask, position):\n",
    "    assert position == 'encoder' or position == 'decoderI' or position == 'decoderII'\n",
    "    if position == 'encoder':\n",
    "        padding_mask = torch.bmm(padding_mask.float(), padding_mask.transpose(1, 2).float())\n",
    "        mask = padding_mask * mask\n",
    "    elif position == 'decoderI':\n",
    "        padding_mask = torch.bmm(padding_mask.float(), padding_mask.transpose(1, 2).float())\n",
    "        mask = padding_mask * mask\n",
    "    else:\n",
    "        mask = torch.bmm(mask.float(), padding_mask.transpose(1, 2).float())\n",
    "    return mask.long().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abfd7e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "src_vocab_size = len(vocab_transform[SRC_LANGUAGE])\n",
    "tgt_vocab_size = len(vocab_transform[TGT_LANGUAGE])\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = 512\n",
    "batch_size = 128\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.1\n",
    "\n",
    "transformer = Seq2SeqTransformer(num_encoder_layers, num_decoder_layers, d_model, d_ff, src_vocab_size, tgt_vocab_size, num_heads, dropout)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13839dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from typing import List\n",
    "\n",
    "def sequential_transform(*transforms):\n",
    "    def func(tokens_input):\n",
    "        for transform in transforms:\n",
    "            tokens_input = transform(tokens_input)\n",
    "        return tokens_input\n",
    "    return func\n",
    "\n",
    "def tensor_transform(tokens_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                     torch.tensor(tokens_ids),\n",
    "                     torch.tensor([EOS_IDX])))\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transform(vocab_transform[ln],\n",
    "                                              tensor_transform)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    \n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c13d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_iter = [i for i in zip(jp_tokenized, vi_tokenized)]\n",
    "    for i in range(0, len(train_iter), 10000):\n",
    "        if i == 100000:\n",
    "            train_dataloader = DataLoader(train_iter[i:], batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        else:\n",
    "            train_dataloader = DataLoader(train_iter[i:i+10000], batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        for src, tgt in train_dataloader:\n",
    "            src = src.transpose(0, 1).to(DEVICE)\n",
    "            tgt = tgt.transpose(0, 1).to(DEVICE)\n",
    "\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            src_mask, tgt_mask = create_mask(src, 'src'), create_mask(tgt_input, 'tgt')\n",
    "            src_padding_mask, tgt_padding_mask = create_padding_mask(src), create_padding_mask(tgt_input)\n",
    "            src_mask = create_std_mask(src_padding_mask, src_mask, 'encoder').long()\n",
    "            tgt_mask = create_std_mask(tgt_padding_mask, tgt_mask, 'decoderI').long()\n",
    "            last_mask = create_std_mask(src_padding_mask, tgt_padding_mask, 'decoderII').long()\n",
    "\n",
    "            logits = model(src, tgt_input, src_mask , tgt_mask, last_mask)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            tgt_out = tgt[:, 1:]\n",
    "\n",
    "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            losses += loss.item()\n",
    "    return losses / len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7a1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77f06dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, max_len, start_symbol, src_mask=None):\n",
    "    src = src.to(DEVICE)\n",
    "    memory =  model.encode(src, src_mask).to(DEVICE)\n",
    "\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "       \n",
    "      \n",
    "        out = model.decode(ys.reshape(1, -1), None, memory)\n",
    "        prob = out[:, -1]\n",
    "        _, next_word = torch.max(prob, dim=-1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c17cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src_token = [str(i) for i in jp_tokenizer(src_sentence)]\n",
    "    src = text_transform[SRC_LANGUAGE](src_token).unsqueeze(0)\n",
    "    num_tokens = src.shape[-1]\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, src, max_len=num_tokens + 5, start_symbol=BOS_IDX)\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"_\", ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a912eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
